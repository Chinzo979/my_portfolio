{
    "computer-vision": {
      "title": "Aerial Object Detection",
      "intro": "Conducted as a Computer Vision Co‑op at AirWorks, this project detects and classifies objects in high-resolution aerial imagery using the DOTA-v1.0 dataset, covering 14 categories such as vehicles, ships, and buildings.",
      "design": "The end-to-end pipeline begins by ingesting 2,806 ultra-high-resolution aerial images. We first tile each image into 800×800 patches, generate oriented bounding box (OBB) annotations from DOTA labels, and normalize coordinates. The core detection model is an LSKNet (Large-Selective-Kernel Network) that dynamically adjusts receptive fields via split-attention: small kernels capture fine-grained details (e.g., small vehicles) while larger kernels capture context for big structures (e.g., airports). Post-processing applies rotated non-max suppression to resolve overlapping detections, and a custom scale-aware head filters false positives based on object size distributions.",
      "implementation": "All components are implemented in Python 3.8. Preprocessing uses OpenCV for tiling and affine transforms, and pandas for annotation management. The detection backbone uses PyTorch and Detectron2, configured via YAML for mask‑RCNN style data loaders adapted for OBB inputs. Training ran on an NVIDIA L4 GPU for 270,000 iterations, using AdamW with cosine annealing lr schedule. We applied random rotations, horizontal flips, and color jitter for augmentation. Inference is packaged in a Docker container (Ubuntu 20.04, CUDA 11.3) with a REST API built using FastAPI, enabling 10 FPS on live AirWorks streams.",
      "results": "On the DOTA-v1.0 validation set, the model achieved 84.2% mAP overall—92.5% on large objects (planes, ships) and 78.4% on small objects (vehicles, storage tanks). Precision‑recall curves indicate strong low‑false positive rates for discrete classes. A live demo processed real aerial footage at 10 FPS with 0.05 false positives per frame, meeting AirWorks performance targets.",
      "future": "Next steps include expanding the small-object training set via targeted data augmentation, integrating temporal information from video streams to smooth detections, and deploying optimized TensorRT engines for edge devices. We also plan to expose a streaming gRPC interface for real-time analytics and implement an auto‑labeling feedback loop for continuous model improvement."
    },
    "anime-recommender": {
      "title": "Anime Recommender System",
      "intro": "Built a production-ready anime recommendation engine using collaborative filtering, content-based models, and hybrid blending on the MyAnimeList dataset, delivering personalized suggestions via a React dashboard.",
      "design": "Data ingestion starts with MAL REST API pulls for user ratings and metadata, supplemented by HTML scraping via BeautifulSoup for missing tags. The pipeline—orchestrated in Airflow—cleans and normalizes fields, one-hot encodes multi-genre tags, and computes TF–IDF vectors on anime synopses. Collaborative filtering uses Surprise’s SVDpp for user–item latent factors, while content-based filtering computes cosine similarity on synopsis embeddings generated by a pre-trained BERT model. A hybrid scorer blends the two with a tunable λ parameter determined via grid search on RMSE and precision@k.",
      "implementation": "Core data processing is in Python 3.9 with pandas and NumPy; model training uses SciPy and TensorFlow (for BERT embeddings) and Surprise (for SVDpp). Model artifacts and Annoy indices (for fast nearest-neighbor lookups) are serialized with pickle. Microservices are containerized with Docker Compose: Flask serves the SVD model, FastAPI serves BERT-based similarity queries, and a React front end uses Axios and Fuse.js for live search/autocomplete. CI/CD is configured via GitHub Actions—unit tests, linting, and Docker image builds run on every commit.",
      "results": "On a held-out test set of 50,000 user–anime pairs, the hybrid model achieved an RMSE of 0.92 and precision@10 of 0.42, outperforming popularity baselines by 25%. End-to-end latency remains under 80 ms per recommendation request. User testing with 20 beta users indicated a 30% increase in engagement compared to static top-10 lists.",
      "future": "Planned enhancements include sentiment analysis on user reviews to weight ratings, real-time online learning via incremental SVDpp updates, Redis caching for most frequent queries, and expansion to mobile clients through React Native. We also aim to introduce an A/B testing framework to optimize the hybrid blending parameter dynamically."
    },
    "search-engine": {
      "title": "Scalable Search Engine",
      "intro": "One of my favorite courses at the University of Michigan was EECS 485 - Web Systems. An end-to-end search engine pipeline that crawls Wikipedia, constructs a segmented inverted index via MapReduce, and serves customizable queries through Flask APIs, showcased by a Google‑style UI.",
      "design": "The inverted index construction involves nine Hadoop‑style MapReduce stages orchestrated by pipeline.sh. Map1 parses raw HTML with BeautifulSoup to extract docID and text, cleans non‑alphanumeric characters via regex, and emits term frequencies. Subsequent jobs compute global document counts, tf–idf weights (using log base‑10), and normalization factors. A custom partitioner (partition.py) shards postings by docID % 3 into three segments. PageRank integration is computed offline and merged with tf–idf scores via a weighted linear combination.",
      "implementation": "Each mapper (map0.py…map8.py) and reducer (reduce0.py…reduce8.py) is a standalone Python script with shebang for Hadoop Streaming. The pipeline runs under Madoop on a Linux cluster. Three Flask segment servers (ports 9000–9002) load their index slice into memory at startup and expose /api/v1/hits/?q=&w= endpoints. The search server uses Python’s requests and threading modules to query all segments in parallel, merges results with heapq.merge, and retrieves document metadata from a SQLite database populated by searchdb (using BeautifulSoup for summaries). UI templates employ Jinja2 and vanilla JS for slider-controlled PageRank weighting.",
      "results": "Query latency averages 120 ms across three segment calls, with 95% of requests under 200 ms under moderate load. Relevance measured by nDCG@10 is 0.78 on a set of 1,000 Wikipedia queries, demonstrating effective blending of tf–idf and PageRank. System scales linearly with added segment servers.",
      "future": "Future improvements include adding phrase and proximity query support via positional indexes, implementing word stemming and synonym expansion, migrating the front end to a React-based SPA, deploying backend services in Docker/Kubernetes clusters with horizontal autoscaling, and introducing Redis‑based caching for hot queries to reduce repeated computation."
    }
  }
  